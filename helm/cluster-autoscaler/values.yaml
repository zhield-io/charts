# Release naming rules.
nameOverride: ""
fullnameOverride: ""
tlsSecretName: "cas-cert"
clusterName: "cluster-local"
# 1 to 5; higher is more verbose
loggingLevel: 5
# timeout for all CCP interactions
grpcTimeout: "300s"
# Use cert-manager to dynamically issue the TLS certificate for the service
certManager:
  enabled: false
  localDomain: cluster.local
  issuerRef:
    name: ca-issuer
    kind: Issuer # or ClusterIssuer
    group: cert-manager.io
  duration: 2160h # 90d
  renewBefore: 360h # 15d
  isCA: false
  usages:
    - server auth
    - client auth
  dnsNames: []
ccpEndpoint: "ccp.kube-system.svc:9090"
replicaCount: 1
revisionHistoryLimit: 3
service:
  create: true
  port: 8085
  portName: http
  type: ClusterIP
image:
  repository: registry.k8s.io/autoscaling/cluster-autoscaler
  tag: 1.33.3
  pullPolicy: IfNotPresent
  # Image registry credentials, provided as a simple list.
  # https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  pullSecrets: []
  # - my-registry
rbac:
  create: true
  pspEnabled: false
  serviceAccount:
    name: ""
    create: true
    annotations: {}
additionalLabels:
  app: cluster-autoscaler
  k8s-addon: cluster-autoscaler.addons.k8s.io
  k8s-app: cluster-autoscaler
annotations: {}
# https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-are-the-parameters-to-ca
extraArgs:
  emit-per-nodegroup-metrics: true
  enable-proactive-scaleup: true
  expander: least-waste
  logtostderr: true
  stderrthreshold: info
  write-status-configmap: false
  status-config-map-name: autoscaler-cas-status
  scan-interval: 20s
  leader-elect: true
  leader-elect-resource-lock: leases
  skip-nodes-with-local-storage: true
  skip-nodes-with-system-pods: true
  balance-similar-node-groups: true
  min-replica-count: 1
  max-node-provision-time: 10m0s
  scale-down-enabled: true
  scale-down-utilization-threshold: 0.4
  scale-down-non-empty-candidates-count: 30
  scale-down-delay-after-add: 10m
  scale-down-delay-after-delete: 0s
  scale-down-delay-after-failure: 3m
  scale-down-unneeded-time: 10m
  node-deletion-delay-timeout: 2m
  node-deletion-batcher-interval: 0s
